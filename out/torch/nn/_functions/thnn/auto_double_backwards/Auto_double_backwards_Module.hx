/* This file is generated, do not edit! */
package torch.nn._functions.thnn.auto_double_backwards;
@:pythonImport("torch.nn._functions.thnn.auto_double_backwards") extern class Auto_double_backwards_Module {
	static public var __builtins__ : Dynamic;
	static public var __cached__ : Dynamic;
	static public var __doc__ : Dynamic;
	static public var __file__ : Dynamic;
	static public var __loader__ : Dynamic;
	static public var __name__ : Dynamic;
	static public var __package__ : Dynamic;
	static public var __spec__ : Dynamic;
	static public var double_backwards_fns : Dynamic;
	static public function elu_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function gatedlinear_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function hardshrink_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function hardtanh_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function klddivloss_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function l1loss_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function leakyrelu_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function logsigmoid_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function mseloss_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function nllloss_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function smoothl1loss_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function softmarginloss_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function softplus_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function softshrink_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
	static public function threshold_double_backwards(ctx:Dynamic, ggI:Dynamic):Dynamic;
}