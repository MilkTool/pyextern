/* This file is generated, do not edit! */
package theano.tensor.nnet.conv;
@:pythonImport("theano.tensor.nnet.conv") extern class Conv_Module {
	static public var __builtins__ : Dynamic;
	static public var __cached__ : Dynamic;
	static public var __doc__ : Dynamic;
	static public var __docformat__ : Dynamic;
	static public var __file__ : Dynamic;
	static public var __loader__ : Dynamic;
	static public var __name__ : Dynamic;
	static public var __package__ : Dynamic;
	static public var __spec__ : Dynamic;
	static public function _bvalfromboundary(boundary:Dynamic):Dynamic;
	static public var _conv_op_code_a : Dynamic;
	static public var _conv_op_code_unroll_patch : Dynamic;
	static public var _conv_op_code_valid_gemm : Dynamic;
	/**
		out = _convolve2d(in1, in2, flip, mode, boundary, fillvalue)
	**/
	static public function _convolve2d(args:haxe.extern.Rest<Dynamic>):Dynamic;
	static public var _logger : Dynamic;
	static public function _valfrommode(mode:Dynamic):Dynamic;
	static public var absolute_import : Dynamic;
	/**
		Return `x`, transformed into a `TensorType`.
		
		This function is often used by `make_node` methods of `Op` subclasses
		to turn ndarrays, numbers, `Scalar` instances, `Apply` instances and
		`TensorType` instances into valid input list elements.
		
		Parameters
		----------
		x : Apply instance, Variable instance, numpy.ndarray, or number
		    This thing will be transformed into a `Variable` in a sensible way. An
		    ndarray argument will not be copied, but a list of numbers will be
		    copied to make an ndarray.
		name : str or None
		    If a new `Variable` instance is created, it will be named with this
		    string.
		ndim : None or integer
		    Return a Variable with this many dimensions.
		
		Raises
		------
		ValueError
		    If an `Apply` with more than one output is fetched or
		    if `x` cannot be made into a Variable with `ndim` dimensions.
		AsTensorError
		    If `x` cannot be converted to a TensorType Variable.
	**/
	static public function as_tensor_variable(x:Dynamic, ?name:Dynamic, ?ndim:Dynamic):Dynamic;
	/**
		Deprecated, old conv2d interface.
		This function will build the symbolic graph for convolving a stack of
		input images with a set of filters. The implementation is modelled after
		Convolutional Neural Networks (CNN). It is simply a wrapper to the ConvOp
		but provides a much cleaner interface.
		
		Parameters
		----------
		input : symbolic 4D tensor
		    Mini-batch of feature map stacks, of shape
		    (batch size, stack size, nb row, nb col)
		    see the optional parameter image_shape
		filters: symbolic 4D tensor
		    Set of filters used in CNN layer of shape
		    (nb filters, stack size, nb row, nb col)
		    see the optional parameter filter_shape
		border_mode : {'valid', 'full'}
		   'valid'only apply filter to complete patches of the image. Generates
		   output of shape: image_shape - filter_shape + 1.
		   'full' zero-pads image to multiple of filter shape to generate output
		   of shape: image_shape + filter_shape - 1.
		subsample: tuple of len 2
		    Factor by which to subsample the output. Also called strides elsewhere.
		image_shape: None, tuple/list of len 4 of int, None or Constant variable
		    The shape of the input parameter.
		    Optional, used for optimization like loop unrolling
		    You can put None for any element of the list to tell that this element
		    is not constant.
		filter_shape : None, tuple/list of len 4 of int, None or Constant variable
		    Optional, used for optimization like loop unrolling
		    You can put None for any element of the list
		    to tell that this element is not constant.
		kwargs
		    Kwargs are passed onto ConvOp. Can be used to set the following:
		    unroll_batch, unroll_kern, unroll_patch, openmp (see ConvOp doc).
		
		    openmp: By default have the same value as
		            config.openmp. For small image, filter,
		            batch size, nkern and stack size, it can be
		            faster to disable manually openmp. A fast and
		            incomplete test show that with image size
		            6x6, filter size 4x4, batch size==1,
		            n kern==1 and stack size==1, it is faster
		            to disable it in valid mode. But if we
		            grow the batch size to 10, it is faster
		            with openmp on a core 2 duo.
		
		Returns
		-------
		symbolic 4D tensor
		    Set of feature maps generated by convolutional layer. Tensor is
		    of shape (batch size, nb filters, output row, output col).
	**/
	static public function conv2d(input:Dynamic, filters:Dynamic, ?image_shape:Dynamic, ?filter_shape:Dynamic, ?border_mode:Dynamic, ?subsample:Dynamic, ?kargs:python.KwArgs<Dynamic>):Dynamic;
	static public var division : Dynamic;
	/**
		c_code for ConvOp that unroll the batch size loop.
	**/
	static public function gen_conv_code_unroll_batch_kern(d:Dynamic, ?unroll_bsize:Dynamic, ?unroll_ksize:Dynamic):Dynamic;
	/**
		This function compute the output shape of convolution operation.
		
		Parameters
		----------
		image_shape: tuple of int (symbolic or numeric) corresponding to the input
		    image shape. Its four (or five) element must correspond respectively
		    to: batch size, number of input channels, height and width (and
		    possibly depth) of the image. None where undefined.
		kernel_shape: tuple of int (symbolic or numeric) corresponding to the
		    kernel shape. For a normal convolution, its four (for 2D convolution)
		    or five (for 3D convolution) elements must correspond respectively to :
		    number of output channels, number of input channels, height and width
		    (and possibly depth) of the kernel.
		    For an unshared 2D convolution, its six channels must correspond to :
		    number of output channels, height and width of the output, number of
		    input channels, height and width of the kernel.
		    None where undefined.
		border_mode: string, int (symbolic or numeric) or tuple of int (symbolic
		    or numeric) or pairs of ints. If it is a string, it must be 'valid',
		    'half' or 'full'. If it is a tuple, its two (or three) elements respectively
		    correspond to the padding on height and width (and possibly depth)
		    axis. For asymmetric padding, provide a pair of ints for each dimension.
		subsample: tuple of int (symbolic or numeric). Its two or three elements
		    espectively correspond to the subsampling on height and width (and
		    possibly depth) axis.
		filter_dilation: tuple of int (symbolic or numeric). Its two or three
		    elements correspond respectively to the dilation on height and width axis.
		Note - The shape of the convolution output does not depend on the 'unshared'
		    or the 'num_groups' parameters.
		
		Returns
		-------
		output_shape: tuple of int corresponding to the output image shape. Its
		    four element must correspond respectively to: batch size, number of
		    output channels, height and width of the image. None where undefined.
	**/
	static public function get_conv_output_shape(image_shape:Dynamic, kernel_shape:Dynamic, border_mode:Dynamic, subsample:Dynamic, ?filter_dilation:Dynamic):Dynamic;
	/**
		This function compute the output shape of convolution operation.
		
		Parameters
		----------
		image_shape: int or None. Corresponds to the input image shape on a
		    given axis. None if undefined.
		kernel_shape: int or None. Corresponds to the kernel shape on a given
		    axis. None if undefined.
		border_mode: string, int or tuple of 2 ints. If it is a string, it must be
		    'valid', 'half' or 'full'. If it is an integer, it must correspond to
		    the padding on the considered axis. If it is a tuple, its two elements
		    must correspond to the asymmetric padding (e.g., left and right) on
		    the considered axis.
		subsample: int. It must correspond to the subsampling on the
		    considered axis.
		dilation: int. It must correspond to the dilation on the
		    considered axis.
		
		Returns
		-------
		out_shp: int corresponding to the output image shape on the
		    considered axis. None if undefined.
	**/
	static public function get_conv_shape_1axis(image_shape:Dynamic, kernel_shape:Dynamic, border_mode:Dynamic, subsample:Dynamic, ?dilation:Dynamic):Dynamic;
	/**
		Return the constant scalar(0-D) value underlying variable `v`.
		
		If `v` is the output of dimshuffles, fills, allocs, rebroadcasts,
		cast, OutputGuard, DeepCopyOp, ScalarFromTensor, ScalarOp, Elemwise
		and some pattern with Subtensor, this function digs through them.
		
		If `v` is not some view of constant scalar data, then raise a
		NotScalarConstantError.
		
		Parameters
		----------
		elemwise : bool
		    If False, we won't try to go into elemwise. So this call is faster.
		    But we still investigate in Second Elemwise (as this is a substitute
		    for Alloc)
		only_process_constants : bool
		    If True, we only attempt to obtain the value of `orig_v` if it's
		    directly constant and don't try to dig through dimshuffles, fills,
		    allocs, and other to figure out its value.
		max_recur : int
		    The maximum number of recursion.
		
		Notes
		-----
		    There may be another function similar to this one in the code,
		    but I'm not sure where it is.
	**/
	static public function get_scalar_constant_value(orig_v:Dynamic, ?elemwise:Dynamic, ?only_process_constants:Dynamic, ?max_recur:Dynamic):Dynamic;
	static public var imported_scipy_signal : Dynamic;
	/**
		Make the input adopt a specific broadcasting pattern.
		
		Broadcastable must be iterable. For example,
		patternbroadcast(x, (True, False)) will make the first
		dimension of x broadcastable and the second dimension
		not broadcastable, so x will now be a row.
		
		We apply the opt here not to pollute the graph especially during the gpu
		optimization.
		
		Parameters
		----------
		x : tensor_like
		    Input theano tensor.
		broadcastable : an iterable object such as list or tuple of bool values
		    A set of boolean values indicating whether a dimension should be
		    broadcastable or not. If the length of x along these dimensions is
		    not 1, a ValueError will be raised.
		
		Returns
		-------
		tensor
		    A theano tensor, which is unbroadcastable along the specified dimensions.
	**/
	static public function patternbroadcast(x:Dynamic, broadcastable:Dynamic):Dynamic;
	static public var print_function : Dynamic;
}