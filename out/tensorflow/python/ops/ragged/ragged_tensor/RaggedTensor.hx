/* This file is generated, do not edit! */
package tensorflow.python.ops.ragged.ragged_tensor;
@:pythonImport("tensorflow.python.ops.ragged.ragged_tensor", "RaggedTensor") extern class RaggedTensor {
	/**
		Computes the absolute value of a tensor.
		
		Given a tensor `x` of complex numbers, this operation returns a tensor of type
		`float32` or `float64` that is the absolute value of each element in `x`. All
		elements in `x` must be complex numbers of the form \\(a + bj\\). The
		absolute value is computed as \\( \sqrt{a^2 + b^2}\\).  For example:
		```python
		x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])
		tf.abs(x)  # [5.25594902, 6.60492229]
		```
		
		Args:
		  x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,
		    `int32`, `int64`, `complex64` or `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` or `SparseTensor` the same size and type as `x` with absolute
		    values.
		  Note, for `complex64` or `complex128` input, the returned `Tensor` will be
		    of type `float32` or `float64`, respectively.
		
		  If `x` is a `SparseTensor`, returns
		  `SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)`
	**/
	static public function __abs__(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x + y element-wise.
		
		*NOTE*: `math.add` supports broadcasting. `AddN` does not. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `string`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function __add__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of x AND y element-wise.
		
		*NOTE*: `math.logical_and` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor` of type `bool`.
		  y: A `Tensor` of type `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function __and__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Dummy method to prevent a RaggedTensor from being used as a Python bool.
	**/
	static public function __bool__(_:Dynamic):Dynamic;
	public function __class__(args:haxe.extern.Rest<Dynamic>):Dynamic;
	/**
		Implement delattr(self, name).
	**/
	public function __delattr__(name:Dynamic):Dynamic;
	static public var __dict__ : Dynamic;
	/**
		__dir__() -> list
		default dir() implementation
	**/
	public function __dir__(args:haxe.extern.Rest<Dynamic>):Dynamic;
	/**
		Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)
		
		Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
		Instructions for updating:
		Deprecated in favor of operator or tf.math.divide.
		
		NOTE: Prefer using the Tensor division operator or tf.divide which obey Python
		division operator semantics.
		
		This function divides `x` and `y`, forcing Python 2.7 semantics. That is,
		if one of `x` or `y` is a float, then the result will be a float.
		Otherwise, the output will be an integer type. Flooring semantics are used
		for integer division.
		
		Args:
		  x: `Tensor` numerator of real numeric type.
		  y: `Tensor` denominator of real numeric type.
		  name: A name for the operation (optional).
		Returns:
		  `x / y` returns the quotient of x and y.
	**/
	static public function __div__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	static public var __doc__ : Dynamic;
	/**
		Return self==value.
	**/
	public function __eq__(value:Dynamic):Dynamic;
	/**
		Divides `x / y` elementwise, rounding toward the most negative integer.
		
		The same as `tf.div(x,y)` for integers, but uses `tf.floor(tf.div(x,y))` for
		floating point arguments so that the result is always an integer (though
		possibly an integer represented as floating point).  This op is generated by
		`x // y` floor division in Python 3 and in Python 2.7 with
		`from __future__ import division`.
		
		`x` and `y` must have the same type, and the result will have the same type
		as well.
		
		Args:
		  x: `Tensor` numerator of real numeric type.
		  y: `Tensor` denominator of real numeric type.
		  name: A name for the operation (optional).
		
		Returns:
		  `x / y` rounded down.
		
		Raises:
		  TypeError: If the inputs are complex.
	**/
	static public function __floordiv__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		default object formatter
	**/
	public function __format__(args:haxe.extern.Rest<Dynamic>):Dynamic;
	/**
		Returns the truth value of (x >= y) element-wise.
		
		*NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function __ge__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return getattr(self, name).
	**/
	public function __getattribute__(name:Dynamic):Dynamic;
	/**
		Returns the specified piece of this RaggedTensor.
		
		Supports multidimensional indexing and slicing, with one restriction:
		indexing into a ragged inner dimension is not allowed.  This case is
		problematic because the indicated value may exist in some rows but not
		others.  In such cases, it's not obvious whether we should (1) report an
		IndexError; (2) use a default value; or (3) skip that value and return a
		tensor with fewer rows than we started with.  Following the guiding
		principles of Python ("In the face of ambiguity, refuse the temptation to
		guess"), we simply disallow this operation.
		
		Any dimensions added by `array_ops.newaxis` will be ragged if the following
		dimension is ragged.
		
		Args:
		  self: The RaggedTensor to slice.
		  key: Indicates which piece of the RaggedTensor to return, using standard
		    Python semantics (e.g., negative values index from the end).  `key`
		    may have any of the following types:
		
		    * `int` constant
		    * Scalar integer `Tensor`
		    * `slice` containing integer constants and/or scalar integer
		      `Tensor`s
		    * `Ellipsis`
		    * `tf.newaxis`
		    * `tuple` containing any of the above (for multidimentional indexing)
		
		Returns:
		  A `Tensor` or `RaggedTensor` object.  Values that include at least one
		  ragged dimension are returned as `RaggedTensor`.  Values that include no
		  ragged dimensions are returned as `Tensor`.  See above for examples of
		  expressions that return `Tensor`s vs `RaggedTensor`s.
		
		Raises:
		  ValueError: If `key` is out of bounds.
		  ValueError: If `key` is not supported.
		  TypeError: If the indices in `key` have an unsupported type.
		
		Examples:
		
		  ```python
		  >>> # A 2-D ragged tensor with 1 ragged dimension.
		  >>> rt = ragged.constant([['a', 'b', 'c'], ['d', 'e'], ['f'], ['g']])
		  >>> rt[0].eval().tolist()       # First row (1-D `Tensor`)
		  ['a', 'b', 'c']
		  >>> rt[:3].eval().tolist()      # First three rows (2-D RaggedTensor)
		  [['a', 'b', 'c'], ['d', 'e'], '[f'], [g']]
		  >>> rt[3, 0].eval().tolist()    # 1st element of 4th row (scalar)
		  'g'
		
		  >>> # A 3-D ragged tensor with 2 ragged dimensions.
		  >>> rt = ragged.constant([[[1, 2, 3], [4]],
		  ...                    [[5], [], [6]],
		  ...                    [[7]],
		  ...                    [[8, 9], [10]]])
		  >>> rt[1].eval().tolist()       # Second row (2-D RaggedTensor)
		  [[5], [], [6]]
		  >>> rt[3, 0].eval().tolist()    # First element of fourth row (1-D Tensor)
		  [8, 9]
		  >>> rt[:, 1:3].eval().tolist()  # Items 1-3 of each row (3-D RaggedTensor)
		  [[[4]], [[], [6]], [], [[10]]]
		  >>> rt[:, -1:].eval().tolist()  # Last item of each row (3-D RaggedTensor)
		  [[[4]], [[6]], [[7]], [[10]]]
		  ```
	**/
	public function __getitem__(key:Dynamic):Dynamic;
	/**
		Returns the truth value of (x > y) element-wise.
		
		*NOTE*: `math.greater` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function __gt__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return hash(self).
	**/
	public function __hash__():Dynamic;
	/**
		Creates a `RaggedTensor` with a specified partitioning for `values`.
		
		This constructor is private -- please use one of the following ops to
		build `RaggedTensor`s:
		
		  * `tf.RaggedTensor.from_row_lengths`
		  * `tf.RaggedTensor.from_value_rowids`
		  * `tf.RaggedTensor.from_row_splits`
		  * `tf.RaggedTensor.from_row_starts`
		  * `tf.RaggedTensor.from_row_limits`
		  * `tf.RaggedTensor.from_nested_row_splits`
		  * `tf.RaggedTensor.from_nested_row_lengths`
		  * `tf.RaggedTensor.from_nested_value_rowids`
		
		Args:
		  values: A potentially ragged tensor of any dtype and shape `[nvals, ...]`.
		  row_splits: A 1-D int64 tensor with shape `[nrows+1]`.
		  cached_row_lengths: A 1-D int64 tensor with shape `[nrows]`
		  cached_value_rowids: A 1-D int64 tensor with shape `[nvals]`.
		  cached_nrows: A 1-D int64 scalar tensor.
		  internal: True if the constructor is being called by one of the factory
		    methods.  If false, an exception will be raised.
		
		Raises:
		  TypeError: If a row partitioning tensor has an inappropriate dtype.
		  TypeError: If exactly one row partitioning argument was not specified.
		  ValueError: If a row partitioning tensor has an inappropriate shape.
		  ValueError: If multiple partitioning arguments are specified.
		  ValueError: If nrows is specified but value_rowids is not None.
	**/
	@:native("__init__")
	public function ___init__(values:Dynamic, row_splits:Dynamic, ?cached_row_lengths:Dynamic, ?cached_value_rowids:Dynamic, ?cached_nrows:Dynamic, ?internal:Dynamic):Dynamic;
	/**
		Creates a `RaggedTensor` with a specified partitioning for `values`.
		
		This constructor is private -- please use one of the following ops to
		build `RaggedTensor`s:
		
		  * `tf.RaggedTensor.from_row_lengths`
		  * `tf.RaggedTensor.from_value_rowids`
		  * `tf.RaggedTensor.from_row_splits`
		  * `tf.RaggedTensor.from_row_starts`
		  * `tf.RaggedTensor.from_row_limits`
		  * `tf.RaggedTensor.from_nested_row_splits`
		  * `tf.RaggedTensor.from_nested_row_lengths`
		  * `tf.RaggedTensor.from_nested_value_rowids`
		
		Args:
		  values: A potentially ragged tensor of any dtype and shape `[nvals, ...]`.
		  row_splits: A 1-D int64 tensor with shape `[nrows+1]`.
		  cached_row_lengths: A 1-D int64 tensor with shape `[nrows]`
		  cached_value_rowids: A 1-D int64 tensor with shape `[nvals]`.
		  cached_nrows: A 1-D int64 scalar tensor.
		  internal: True if the constructor is being called by one of the factory
		    methods.  If false, an exception will be raised.
		
		Raises:
		  TypeError: If a row partitioning tensor has an inappropriate dtype.
		  TypeError: If exactly one row partitioning argument was not specified.
		  ValueError: If a row partitioning tensor has an inappropriate shape.
		  ValueError: If multiple partitioning arguments are specified.
		  ValueError: If nrows is specified but value_rowids is not None.
	**/
	public function new(values:Dynamic, row_splits:Dynamic, ?cached_row_lengths:Dynamic, ?cached_value_rowids:Dynamic, ?cached_nrows:Dynamic, ?internal:Dynamic):Void;
	/**
		This method is called when a class is subclassed.
		
		The default implementation does nothing. It may be
		overridden to extend subclasses.
	**/
	public function __init_subclass__(args:haxe.extern.Rest<Dynamic>):Dynamic;
	/**
		Returns the truth value of NOT x element-wise.
		
		Args:
		  x: A `Tensor` of type `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function __invert__(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of (x <= y) element-wise.
		
		*NOTE*: `math.less_equal` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function __le__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of (x < y) element-wise.
		
		*NOTE*: `math.less` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function __lt__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns element-wise remainder of division. When `x < 0` xor `y < 0` is
		
		true, this follows Python semantics in that the result here is consistent
		with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.
		
		*NOTE*: `floormod` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function __mod__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	static public var __module__ : Dynamic;
	/**
		Returns x * y element-wise.
		
		*NOTE*: ``tf.multiply`` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function __mul__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return self!=value.
	**/
	public function __ne__(value:Dynamic):Dynamic;
	/**
		Computes numerical negative value element-wise.
		
		I.e., \\(y = -x\\).
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
		
		  If `x` is a `SparseTensor`, returns
		  `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`
	**/
	static public function __neg__(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Create and return a new object.  See help(type) for accurate signature.
	**/
	static public function __new__(?args:python.VarArgs<Dynamic>, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Dummy method to prevent a RaggedTensor from being used as a Python bool.
	**/
	static public function __nonzero__(_:Dynamic):Dynamic;
	/**
		Returns the truth value of x OR y element-wise.
		
		*NOTE*: `math.logical_or` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor` of type `bool`.
		  y: A `Tensor` of type `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function __or__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the power of one value to another.
		
		Given a tensor `x` and a tensor `y`, this operation computes \\(x^y\\) for
		corresponding elements in `x` and `y`. For example:
		
		```python
		x = tf.constant([[2, 2], [3, 3]])
		y = tf.constant([[8, 16], [2, 3]])
		tf.pow(x, y)  # [[256, 65536], [9, 27]]
		```
		
		Args:
		  x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,
		   `complex64`, or `complex128`.
		  y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,
		   `complex64`, or `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`.
	**/
	static public function __pow__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x + y element-wise.
		
		*NOTE*: `math.add` supports broadcasting. `AddN` does not. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `string`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function __radd__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of x AND y element-wise.
		
		*NOTE*: `math.logical_and` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor` of type `bool`.
		  y: A `Tensor` of type `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function __rand__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)
		
		Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.
		Instructions for updating:
		Deprecated in favor of operator or tf.math.divide.
		
		NOTE: Prefer using the Tensor division operator or tf.divide which obey Python
		division operator semantics.
		
		This function divides `x` and `y`, forcing Python 2.7 semantics. That is,
		if one of `x` or `y` is a float, then the result will be a float.
		Otherwise, the output will be an integer type. Flooring semantics are used
		for integer division.
		
		Args:
		  x: `Tensor` numerator of real numeric type.
		  y: `Tensor` denominator of real numeric type.
		  name: A name for the operation (optional).
		Returns:
		  `x / y` returns the quotient of x and y.
	**/
	static public function __rdiv__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		helper for pickle
	**/
	public function __reduce__(args:haxe.extern.Rest<Dynamic>):Dynamic;
	/**
		helper for pickle
	**/
	public function __reduce_ex__(args:haxe.extern.Rest<Dynamic>):Dynamic;
	/**
		Return repr(self).
	**/
	public function __repr__():Dynamic;
	/**
		Divides `x / y` elementwise, rounding toward the most negative integer.
		
		The same as `tf.div(x,y)` for integers, but uses `tf.floor(tf.div(x,y))` for
		floating point arguments so that the result is always an integer (though
		possibly an integer represented as floating point).  This op is generated by
		`x // y` floor division in Python 3 and in Python 2.7 with
		`from __future__ import division`.
		
		`x` and `y` must have the same type, and the result will have the same type
		as well.
		
		Args:
		  x: `Tensor` numerator of real numeric type.
		  y: `Tensor` denominator of real numeric type.
		  name: A name for the operation (optional).
		
		Returns:
		  `x / y` rounded down.
		
		Raises:
		  TypeError: If the inputs are complex.
	**/
	static public function __rfloordiv__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns element-wise remainder of division. When `x < 0` xor `y < 0` is
		
		true, this follows Python semantics in that the result here is consistent
		with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.
		
		*NOTE*: `floormod` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function __rmod__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x * y element-wise.
		
		*NOTE*: ``tf.multiply`` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function __rmul__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of x OR y element-wise.
		
		*NOTE*: `math.logical_or` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor` of type `bool`.
		  y: A `Tensor` of type `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function __ror__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the power of one value to another.
		
		Given a tensor `x` and a tensor `y`, this operation computes \\(x^y\\) for
		corresponding elements in `x` and `y`. For example:
		
		```python
		x = tf.constant([[2, 2], [3, 3]])
		y = tf.constant([[8, 16], [2, 3]])
		tf.pow(x, y)  # [[256, 65536], [9, 27]]
		```
		
		Args:
		  x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,
		   `complex64`, or `complex128`.
		  y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,
		   `complex64`, or `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`.
	**/
	static public function __rpow__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x - y element-wise.
		
		*NOTE*: `Subtract` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function __rsub__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Divides x / y elementwise (using Python 3 division operator semantics).
		
		NOTE: Prefer using the Tensor operator or tf.divide which obey Python
		division operator semantics.
		
		This function forces Python 3 division operator semantics where all integer
		arguments are cast to floating types first.   This op is generated by normal
		`x / y` division in Python 3 and in Python 2.7 with
		`from __future__ import division`.  If you want integer division that rounds
		down, use `x // y` or `tf.math.floordiv`.
		
		`x` and `y` must have the same numeric type.  If the inputs are floating
		point, the output will have the same type.  If the inputs are integral, the
		inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`
		and `int64` (matching the behavior of Numpy).
		
		Args:
		  x: `Tensor` numerator of numeric type.
		  y: `Tensor` denominator of numeric type.
		  name: A name for the operation (optional).
		
		Returns:
		  `x / y` evaluated in floating point.
		
		Raises:
		  TypeError: If `x` and `y` have different dtypes.
	**/
	static public function __rtruediv__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		x ^ y = (x | y) & ~(x & y).
	**/
	static public function __rxor__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Implement setattr(self, name, value).
	**/
	public function __setattr__(name:Dynamic, value:Dynamic):Dynamic;
	/**
		__sizeof__() -> int
		size of object in memory, in bytes
	**/
	public function __sizeof__(args:haxe.extern.Rest<Dynamic>):Dynamic;
	/**
		Return str(self).
	**/
	public function __str__():Dynamic;
	/**
		Returns x - y element-wise.
		
		*NOTE*: `Subtract` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function __sub__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Abstract classes can override this to customize issubclass().
		
		This is invoked early on by abc.ABCMeta.__subclasscheck__().
		It should return True, False or NotImplemented.  If it returns
		NotImplemented, the normal algorithm is used.  Otherwise, it
		overrides the normal algorithm (and the outcome is cached).
	**/
	public function __subclasshook__(args:haxe.extern.Rest<Dynamic>):Dynamic;
	/**
		Divides x / y elementwise (using Python 3 division operator semantics).
		
		NOTE: Prefer using the Tensor operator or tf.divide which obey Python
		division operator semantics.
		
		This function forces Python 3 division operator semantics where all integer
		arguments are cast to floating types first.   This op is generated by normal
		`x / y` division in Python 3 and in Python 2.7 with
		`from __future__ import division`.  If you want integer division that rounds
		down, use `x // y` or `tf.math.floordiv`.
		
		`x` and `y` must have the same numeric type.  If the inputs are floating
		point, the output will have the same type.  If the inputs are integral, the
		inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`
		and `int64` (matching the behavior of Numpy).
		
		Args:
		  x: `Tensor` numerator of numeric type.
		  y: `Tensor` denominator of numeric type.
		  name: A name for the operation (optional).
		
		Returns:
		  `x / y` evaluated in floating point.
		
		Raises:
		  TypeError: If `x` and `y` have different dtypes.
	**/
	static public function __truediv__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		list of weak references to the object (if defined)
	**/
	public var __weakref__ : Dynamic;
	/**
		x ^ y = (x | y) & ~(x & y).
	**/
	static public function __xor__(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Convert `self` to a graph element.
	**/
	public function _as_graph_element():Dynamic;
	/**
		Returns a RaggedTensorValue for self.  Requires self._is_eager()=true.
	**/
	public function _eager_value():Dynamic;
	/**
		Returns True if values & row_splits Tensors are all `EagerTensor`s.
	**/
	public function _is_eager():Dynamic;
	static public var _tf_api_names : Dynamic;
	static public var _tf_api_names_v1 : Dynamic;
	/**
		Returns the tight bounding box shape for this `RaggedTensor`.
		
		Args:
		  axis: An integer scalar or vector indicating which axes to return the
		    bounding box for.  If not specified, then the full bounding box is
		    returned.
		  name: A name prefix for the returned tensor (optional).
		
		Returns:
		  An int64 `Tensor`.  If `axis` is not specified, then `output`
		  is a vector with `output.shape=[self.shape.ndims]`.  If `axis` is a
		  scalar, then the `output` is a scalar.  If `axis` is a vector, then
		  `output` is a vector, where `output[i]` is the bounding size for
		  dimension `axis[i]`.
		
		#### Example:
		  ```python
		  >>> rt = ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]])
		  >>> rt.bounding_shape()
		  [5, 4]
		  ```
	**/
	public function bounding_shape(?axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		The `DType` of values in this tensor.
	**/
	public var dtype : Dynamic;
	/**
		The innermost `values` tensor for this ragged tensor.
		
		Concretely, if `rt.values` is a `Tensor`, then `rt.flat_values` is
		`rt.values`; otherwise, `rt.flat_values` is `rt.values.flat_values`.
		
		Conceptually, `flat_values` is the tensor formed by flattening the
		outermost dimension and all of the ragged dimensions into a single
		dimension.
		
		`rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:]`
		(where `nvals` is the number of items in the flattened dimensions).
		
		Returns:
		  A `Tensor`.
		
		#### Example:
		
		  ```python
		  >>> rt = ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])
		  >>> print rt.flat_values()
		  tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])
		  ```
	**/
	public var flat_values : Dynamic;
	/**
		Creates a `RaggedTensor` from a nested list of `row_lengths` tensors.
		
		Equivalent to:
		
		```python
		result = flat_values
		for row_lengths in reversed(nested_row_lengths):
		  result = from_row_lengths(result, row_lengths)
		```
		
		Args:
		  flat_values: A potentially ragged tensor.
		  nested_row_lengths: A list of 1-D int64 tensors.  The `i`th tensor is used
		    as the `row_lengths` for the `i`th ragged dimension.
		  name: A name prefix for the RaggedTensor (optional).
		
		Returns:
		  A `RaggedTensor` (or `flat_values` if `nested_row_lengths` is empty).
	**/
	static public function from_nested_row_lengths(flat_values:Dynamic, nested_row_lengths:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a `RaggedTensor` from a nested list of `row_splits` tensors.
		
		Equivalent to:
		
		```python
		result = flat_values
		for row_splits in reversed(nested_row_splits):
		  result = from_row_splits(result, row_splits)
		```
		
		Args:
		  flat_values: A potentially ragged tensor.
		  nested_row_splits: A list of 1-D int64 tensors.  The `i`th tensor is used
		    as the `row_splits` for the `i`th ragged dimension.
		  name: A name prefix for the RaggedTensor (optional).
		
		Returns:
		  A `RaggedTensor` (or `flat_values` if `nested_row_splits` is empty).
	**/
	static public function from_nested_row_splits(flat_values:Dynamic, nested_row_splits:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a `RaggedTensor` from a nested list of `value_rowids` tensors.
		
		Equivalent to:
		
		```python
		result = flat_values
		for (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):
		  result = from_value_rowids(result, rowids, nrows)
		```
		
		Args:
		  flat_values: A potentially ragged tensor.
		  nested_value_rowids: A list of 1-D int64 tensors.  The `i`th tensor is
		    used as the `value_rowids` for the `i`th ragged dimension.
		  nested_nrows: A list of int64 scalars.  The `i`th scalar is used as the
		    `nrows` for the `i`th ragged dimension.
		  name: A name prefix for the RaggedTensor (optional).
		
		Returns:
		  A `RaggedTensor` (or `flat_values` if `nested_value_rowids` is empty).
		
		Raises:
		  ValueError: If `len(nested_values_rowids) != len(nested_nrows)`.
	**/
	static public function from_nested_value_rowids(flat_values:Dynamic, nested_value_rowids:Dynamic, ?nested_nrows:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a `RaggedTensor` with rows partitioned by `row_lengths`.
		
		The returned `RaggedTensor` corresponds with the python list defined by:
		
		```python
		result = [[values.pop(0) for i in range(length)]
		          for length in row_lengths]
		```
		
		Args:
		  values: A potentially ragged tensor with shape `[nvals, ...]`.
		  row_lengths: A 1-D int64 tensor with shape `[nrows]`.  Must be
		    nonnegative.  `sum(row_lengths)` must be `nvals`.
		  name: A name prefix for the RaggedTensor (optional).
		
		Returns:
		  A `RaggedTensor`.  `result.rank = values.rank + 1`.
		  `result.ragged_rank = values.ragged_rank + 1`.
		
		#### Example:
		  ```python
		  >>> print(tf.RaggedTensor.from_row_lengths(
		  ...     values=[3, 1, 4, 1, 5, 9, 2, 6],
		  ...     row_lengths=[4, 0, 3, 1, 0]))
		  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []])>
		  ```
	**/
	static public function from_row_lengths(values:Dynamic, row_lengths:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a `RaggedTensor` with rows partitioned by `row_limits`.
		
		Equivalent to: `from_row_splits(values, concat([0, row_limits]))`.
		
		Args:
		  values: A potentially ragged tensor with shape `[nvals, ...]`.
		  row_limits: A 1-D int64 tensor with shape `[nrows]`.  Must be sorted in
		    ascending order.  If `nrows>0`, then `row_limits[-1]` must be `nvals`.
		  name: A name prefix for the RaggedTensor (optional).
		
		Returns:
		  A `RaggedTensor`.  `result.rank = values.rank + 1`.
		  `result.ragged_rank = values.ragged_rank + 1`.
		
		#### Example:
		  ```python
		  >>> print(tf.RaggedTensor.from_row_limits(
		  ...     values=[3, 1, 4, 1, 5, 9, 2, 6],
		  ...     row_limits=[4, 4, 7, 8, 8]))
		  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>
		  ```
	**/
	static public function from_row_limits(values:Dynamic, row_limits:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a `RaggedTensor` with rows partitioned by `row_splits`.
		
		The returned `RaggedTensor` corresponds with the python list defined by:
		
		```python
		result = [values[row_splits[i]:row_splits[i + 1]]
		          for i in range(len(row_splits) - 1)]
		```
		
		Args:
		  values: A potentially ragged tensor with shape `[nvals, ...]`.
		  row_splits: A 1-D int64 tensor with shape `[nrows+1]`.  Must not be empty,
		    and must be sorted in ascending order.  `row_splits[0]` must be zero and
		    `row_splits[-1]` must be `nvals`.
		  name: A name prefix for the RaggedTensor (optional).
		
		Returns:
		  A `RaggedTensor`.  `result.rank = values.rank + 1`.
		  `result.ragged_rank = values.ragged_rank + 1`.
		
		Raises:
		  ValueError: If `row_splits` is an empty list.
		
		#### Example:
		  ```python
		  >>> print(tf.RaggedTensor.from_row_splits(
		  ...     values=[3, 1, 4, 1, 5, 9, 2, 6],
		  ...     row_splits=[0, 4, 4, 7, 8, 8]))
		  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>
		  ```
	**/
	static public function from_row_splits(values:Dynamic, row_splits:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a `RaggedTensor` with rows partitioned by `row_starts`.
		
		Equivalent to: `from_row_splits(values, concat([row_starts, nvals]))`.
		
		Args:
		  values: A potentially ragged tensor with shape `[nvals, ...]`.
		  row_starts: A 1-D int64 tensor with shape `[nrows]`.  Must be nonnegative
		    and sorted in ascending order.  If `nrows>0`, then `row_starts[0]` must
		    be zero.
		  name: A name prefix for the RaggedTensor (optional).
		
		Returns:
		  A `RaggedTensor`.  `result.rank = values.rank + 1`.
		  `result.ragged_rank = values.ragged_rank + 1`.
		
		#### Example:
		  ```python
		  >>> print(tf.RaggedTensor.from_row_starts(
		  ...     values=[3, 1, 4, 1, 5, 9, 2, 6],
		  ...     row_starts=[0, 4, 4, 7, 8]))
		  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>
		  ```
	**/
	static public function from_row_starts(values:Dynamic, row_starts:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts a 2D `tf.SparseTensor` to a `RaggedTensor`.
		
		Each row of the `output` `RaggedTensor` will contain the explicit values
		from the same row in `st_input`.  `st_input` must be ragged-right.  If not
		it is not ragged-right, then an error will be generated.
		
		Example:
		
		```python
		>>> st = SparseTensor(indices=[[0, 1], [0, 2], [0, 3], [1, 0], [3, 0]],
		...                   values=[1, 2, 3, 4, 5],
		...                   dense_shape=[4, 3])
		>>> rt.RaggedTensor.from_sparse(st).eval().tolist()
		[[1, 2, 3], [4], [], [5]]
		```
		
		Currently, only two-dimensional `SparseTensors` are supported.
		
		Args:
		  st_input: The sparse tensor to convert.  Must have rank 2.
		  name: A name prefix for the returned tensors (optional).
		
		Returns:
		  A `RaggedTensor` with the same values as `st_input`.
		  `output.ragged_rank = rank(st_input) - 1`.
		  `output.shape = [st_input.dense_shape[0], None]`.
		Raises:
		  ValueError: If the number of dimensions in `st_input` is not known
		    statically, or is not two.
	**/
	static public function from_sparse(st_input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts a `tf.Tensor` into a `RaggedTensor`.
		
		The set of absent/default values may be specified using a vector of lengths
		or a padding value (but not both).  If `lengths` is specified, then the
		output tensor will satisfy `output[row] = tensor[row][:lengths[row]]`.
		If `padding` is specified, then any row *suffix* consisting entirely of
		`padding` will be excluded from the returned `RaggedTensor`.  If neither
		`lengths` nor `padding` is specified, then the returned `RaggedTensor` will
		have no absent/default values.
		
		Examples:
		
		```python
		>>> dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]])
		>>> tf.RaggedTensor.from_tensor(dt)
		<tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]>
		>>> tf.RaggedTensor.from_tensor(dt, lengths=[2, 0, 3])
		<tf.RaggedTensor [[5, 7], [], [6, 0, 0]]>
		>>> tf.RaggedTensor.from_tensor(dt, padding=0)
		<tf.RaggedTensor [[5, 7], [0, 3], [6]]>
		```
		
		Args:
		  tensor: The `Tensor` to convert.  Must have rank `ragged_rank + 1` or
		    higher.
		  lengths: An optional set of row lengths, specified using a 1-D integer
		    `Tensor` whose length is equal to `tensor.shape[0]` (the number of rows
		    in `tensor`).  If specified, then `output[row]` will contain
		    `tensor[row][:lengths[row]]`.  Negative lengths are treated as zero.
		  padding: An optional padding value.  If specified, then any row suffix
		    consisting entirely of `padding` will be excluded from the returned
		    RaggedTensor.  `padding` is a `Tensor` with the same dtype as `tensor`
		    and with `shape=tensor.shape[ragged_rank + 1:]`.
		  ragged_rank: Integer specifying the ragged rank for the returned
		    `RaggedTensor`.  Must be greater than zero.
		  name: A name prefix for the returned tensors (optional).
		
		Returns:
		  A `RaggedTensor` with the specified `ragged_rank`.  The shape of the
		  returned ragged tensor is compatible with the shape of `tensor`.
		Raises:
		  ValueError: If both `lengths` and `padding` are specified.
	**/
	static public function from_tensor(tensor:Dynamic, ?lengths:Dynamic, ?padding:Dynamic, ?ragged_rank:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a `RaggedTensor` with rows partitioned by `value_rowids`.
		
		The returned `RaggedTensor` corresponds with the python list defined by:
		
		```python
		result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]
		          for row in range(nrows)]
		```
		
		Warning: currently, this needs to cast value_rowids to int64 before
		converting, since `tf.bincount` only supports `int32`.
		
		Args:
		  values: A potentially ragged tensor with shape `[nvals, ...]`.
		  value_rowids: A 1-D int64 tensor with shape `[nvals]`, which corresponds
		    one-to-one with `values`, and specifies each value's row index.  Must be
		    nonnegative, and must be sorted in ascending order.
		  nrows: An int64 scalar specifying the number of rows.  This should be
		    specified if the `RaggedTensor` may containing empty training rows. Must
		    be greater than `value_rowids[-1]` (or zero if `value_rowids` is empty).
		    Defaults to `value_rowids[-1]` (or zero if `value_rowids` is empty).
		  name: A name prefix for the RaggedTensor (optional).
		
		Returns:
		  A `RaggedTensor`.  `result.rank = values.rank + 1`.
		  `result.ragged_rank = values.ragged_rank + 1`.
		
		Raises:
		  ValueError: If `nrows` is incompatible with `value_rowids`.
		
		#### Example:
		  ```python
		  >>> print(tf.RaggedTensor.from_value_rowids(
		  ...     values=[3, 1, 4, 1, 5, 9, 2, 6],
		  ...     value_rowids=[0, 0, 0, 0, 2, 2, 2, 3],
		  ...     nrows=5))
		  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>
		  ```
	**/
	static public function from_value_rowids(values:Dynamic, value_rowids:Dynamic, ?nrows:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a tuple containing the row_lengths for all ragged dimensions.
		
		`rtnested_row_lengths()` is a tuple containing the `row_lengths` tensors for
		all ragged dimensions in `rt`, ordered from outermost to innermost.
		
		Args:
		  name: A name prefix for the returned tensors (optional).
		
		Returns:
		  A `tuple` of 1-D `int64` `Tensors`.  The length of the tuple is equal to
		  `self.ragged_rank`.
	**/
	public function nested_row_lengths(?name:Dynamic):Dynamic;
	/**
		A tuple containing the row_splits for all ragged dimensions.
		
		`rt.nested_row_splits` is a tuple containing the `row_splits` tensors for
		all ragged dimensions in `rt`, ordered from outermost to innermost.  In
		particular, `rt.nested_row_splits = (rt.row_splits,) + value_splits` where:
		
		    * `value_splits = ()` if `rt.values` is a `Tensor`.
		    * `value_splits = rt.values.nested_row_splits` otherwise.
		
		Returns:
		  A `tuple` of 1-D `int64` `Tensor`s.
		
		#### Example:
		
		  ```python
		  >>> rt = ragged.constant([[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])
		  >>> for i, splits in enumerate(rt.nested_row_splits()):
		  ...   print('Splits for dimension %d: %s' % (i+1, splits))
		  Splits for dimension 1: [0, 1]
		  Splits for dimension 2: [0, 3, 3, 5]
		  Splits for dimension 3: [0, 4, 4, 7, 8, 8]
		  ```
	**/
	public var nested_row_splits : Dynamic;
	/**
		Returns the number of rows in this ragged tensor.
		
		I.e., the size of the outermost dimension of the tensor.
		
		Args:
		  out_type: `dtype` for the returned tensor.
		  name: A name prefix for the returned tensor (optional).
		
		Returns:
		  A scalar `Tensor` with dtype `out_type`.
		
		#### Example:
		  ```python
		  >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
		  >>> rt.nrows()  # rt has 5 rows.
		  5
		  ```
	**/
	public function nrows(?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		The number of ragged dimensions in this ragged tensor.
		
		Returns:
		  A Python `int` indicating the number of ragged dimensions in this ragged
		  tensor.  The outermost dimension is not considered ragged.
	**/
	public var ragged_rank : Dynamic;
	/**
		Returns the lengths of the rows in this ragged tensor.
		
		`rt.row_lengths()[i]` indicates the number of values in the
		`i`th row of `rt`.
		
		Args:
		  axis: An integer constant indicating the axis whose row lengths should be
		    returned.
		  name: A name prefix for the returned tensor (optional).
		
		Returns:
		  A potentially ragged Tensor of int64 with shape `self.shape[:axis]`.
		
		Raises:
		  ValueError: If `axis` is out of bounds.
		
		#### Example:
		  ```python
		  >>> rt = ragged.constant([[[3, 1, 4], [1]], [], [[5, 9], [2]], [[6]], []])
		  >>> rt.row_lengths(rt)  # lengths of rows in rt
		  tf.Tensor([2, 0, 2, 1, 0])
		  >>> rt.row_lengths(axis=2)  # lengths of axis=2 rows.
		  <tf.RaggedTensor [[3, 1], [], [2, 1], [1], []]>
		  ```
	**/
	public function row_lengths(?axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the limit indices for rows in this ragged tensor.
		
		These indices specify where the values for each row end in
		`self.values`.  `rt.row_limits(self)` is equal to `rt.row_splits[:-1]`.
		
		Args:
		  name: A name prefix for the returned tensor (optional).
		
		Returns:
		  A 1-D Tensor of int64 with shape `[nrows]`.
		  The returned tensor is nonnegative, and is sorted in ascending order.
		
		#### Example:
		  ```python
		  >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
		  >>> rt.values
		  tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])
		  >>> rt.row_limits()  # indices of row limits in rt.values
		  tf.Tensor([4, 4, 7, 8, 8])
		  ```
	**/
	public function row_limits(?name:Dynamic):Dynamic;
	/**
		The row-split indices for this ragged tensor's `values`.
		
		`rt.row_splits` specifies where the values for each row begin and end in
		`rt.values`.  In particular, the values for row `rt[i]` are stored in
		the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.
		
		Returns:
		  A 1-D `int64` `Tensor` with shape `[self.nrows+1]`.
		  The returned tensor is non-empty, and is sorted in ascending order.
		  `self.row_splits[0]` is zero, and `self.row_splits[-1]` is equal to
		  `self.values.shape[0]`.
		
		#### Example:
		  ```python
		  >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
		  >>> print rt.row_splits  # indices of row splits in rt.values
		  tf.Tensor([0, 4, 4, 7, 8, 8])
		  ```
	**/
	public var row_splits : Dynamic;
	/**
		Returns the start indices for rows in this ragged tensor.
		
		These indices specify where the values for each row begin in
		`self.values`.  `rt.row_starts()` is equal to `rt.row_splits[:-1]`.
		
		Args:
		  name: A name prefix for the returned tensor (optional).
		
		Returns:
		  A 1-D Tensor of int64 with shape `[nrows]`.
		  The returned tensor is nonnegative, and is sorted in ascending order.
		
		#### Example:
		  ```python
		  >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
		  >>> rt.values
		  tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])
		  >>> rt.row_starts()  # indices of row starts in rt.values
		  tf.Tensor([0, 4, 4, 7, 8])
		  ```
	**/
	public function row_starts(?name:Dynamic):Dynamic;
	/**
		The statically known shape of this ragged tensor.
		
		Returns:
		  A `TensorShape` containing the statically known shape of this ragged
		  tensor.  Ragged dimensions have a size of `None`.
		
		Examples:
		
		  ```python
		  >>> ragged.constant([[0], [1, 2]]).shape
		  TensorShape([Dimension(2), Dimension(None)])
		
		  >>> ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape
		  TensorShape([Dimension(2), Dimension(None), Dimension(2)
		  ```
	**/
	public var shape : Dynamic;
	/**
		Returns a nested Python `list` with the values for this `RaggedTensor`.
		
		Requires that `rt` was constructed in eager execution mode.
		
		Returns:
		  A nested Python `list`.
	**/
	public function to_list():Dynamic;
	/**
		Converts this `RaggedTensor` into a `tf.SparseTensor`.
		
		Example:
		
		```python
		>>> rt = ragged.constant([[1, 2, 3], [4], [], [5, 6]])
		>>> rt.to_sparse().eval()
		SparseTensorValue(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0], [3, 1]],
		                  values=[1, 2, 3, 4, 5, 6],
		                  dense_shape=[4, 3])
		```
		
		Args:
		  name: A name prefix for the returned tensors (optional).
		
		Returns:
		  A SparseTensor with the same values as `self`.
	**/
	public function to_sparse(?name:Dynamic):Dynamic;
	/**
		Converts this `RaggedTensor` into a `tf.Tensor`.
		
		Example:
		
		```python
		>>> rt = ragged.constant([[9, 8, 7], [], [6, 5], [4]])
		>>> print rt.to_tensor()
		[[9 8 7]
		 [0 0 0]
		 [6 5 0]
		 [4 0 0]]
		```
		
		Args:
		  default_value: Value to set for indices not specified in `self`. Defaults
		    to zero.  `default_value` must be broadcastable to
		    `self.shape[self.ragged_rank + 1:]`.
		  name: A name prefix for the returned tensors (optional).
		
		Returns:
		  A `Tensor` with shape `ragged.bounding_shape(self)` and the
		  values specified by the non-empty values in `self`.  Empty values are
		  assigned `default_value`.
	**/
	public function to_tensor(?default_value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the row indices for the `values` in this ragged tensor.
		
		`rt.value_rowids()` corresponds one-to-one with the outermost dimension of
		`rt.values`, and specifies the row containing each value.  In particular,
		the row `rt[row]` consists of the values `rt.values[j]` where
		`rt.value_rowids()[j] == row`.
		
		Args:
		  name: A name prefix for the returned tensor (optional).
		
		Returns:
		  A 1-D `int64` `Tensor` with shape `self.values.shape[:1]`.
		  The returned tensor is nonnegative, and is sorted in ascending order.
		
		#### Example:
		  ```python
		  >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
		  >>> rt.values
		  tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])
		  >>> rt.value_rowids()
		  tf.Tensor([0, 0, 0, 0, 2, 2, 2, 3])  # corresponds 1:1 with rt.values
		  ```
	**/
	public function value_rowids(?name:Dynamic):Dynamic;
	/**
		The concatenated rows for this ragged tensor.
		
		`rt.values` is a potentially ragged tensor formed by flattening the two
		outermost dimensions of `rt` into a single dimension.
		
		`rt.values.shape = [nvals] + rt.shape[2:]` (where `nvals` is the
		number of items in the outer two dimensions of `rt`).
		
		`rt.ragged_rank = self.ragged_rank - 1`
		
		Returns:
		  A potentially ragged tensor.
		
		#### Example:
		  ```python
		  >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
		  >>> print rt.values
		  tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])
		  ```
	**/
	public var values : Dynamic;
	/**
		Returns a copy of `self` with `flat_values` replaced by `new_value`.
		
		Preserves cached row-partitioning tensors such as `self.cached_nrows` and
		`self.cached_value_rowids` if they have values.
		
		Args:
		  new_values: Potentially ragged tensor that should replace
		  `self.flat_values`.  Must have `rank > 0`, and must have the same
		  number of rows as `self.flat_values`.
		
		Returns:
		  A `RaggedTensor`.
		  `result.rank = self.ragged_rank + new_values.rank`.
		  `result.ragged_rank = self.ragged_rank + new_values.ragged_rank`.
	**/
	public function with_flat_values(new_values:Dynamic):Dynamic;
	/**
		Returns a copy of `self` with `values` replaced by `new_value`.
		
		Preserves cached row-partitioning tensors such as `self.cached_nrows` and
		`self.cached_value_rowids` if they have values.
		
		Args:
		  new_values: Potentially ragged tensor to use as the `values` for the
		    returned `RaggedTensor`.  Must have `rank > 0`, and must have the same
		    number of rows as `self.values`.
		
		Returns:
		  A `RaggedTensor`.  `result.rank = 1 + new_values.rank`.
		  `result.ragged_rank = 1 + new_values.ragged_rank`
	**/
	public function with_values(new_values:Dynamic):Dynamic;
}